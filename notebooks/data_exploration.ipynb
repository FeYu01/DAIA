{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755e8218",
   "metadata": {},
   "source": [
    "# DAIA - Data Exploration Notebook\n",
    "\n",
    "This notebook helps you explore your dataset before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eede1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from utils import load_config\n",
    "from data_loader import load_dataset, split_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd57e60",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../config.yaml')\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"\\nData directory: {config['data']['data_dir']}\")\n",
    "print(f\"Image size: {config['data']['image_size']}\")\n",
    "print(f\"Batch size: {config['data']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7b4c2",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee34b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = '../' + config['data']['data_dir']\n",
    "image_paths, labels = load_dataset(data_dir, config)\n",
    "\n",
    "# Statistics\n",
    "total_images = len(image_paths)\n",
    "real_count = labels.count(0)\n",
    "ai_count = labels.count(1)\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Total images: {total_images}\")\n",
    "print(f\"  Real images: {real_count} ({real_count/total_images*100:.1f}%)\")\n",
    "print(f\"  AI-generated: {ai_count} ({ai_count/total_images*100:.1f}%)\")\n",
    "print(f\"  Balance ratio: {min(real_count, ai_count) / max(real_count, ai_count):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac7eb7",
   "metadata": {},
   "source": [
    "## 3. Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "classes = ['Real', 'AI-Generated']\n",
    "counts = [real_count, ai_count]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(classes, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Number of Images', fontsize=12)\n",
    "ax.set_title('Dataset Class Distribution', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check if balanced\n",
    "if abs(real_count - ai_count) / total_images > 0.2:\n",
    "    print(\"‚ö†Ô∏è  Warning: Dataset is imbalanced! Consider balancing classes.\")\n",
    "else:\n",
    "    print(\"‚úì Dataset is well-balanced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb578159",
   "metadata": {},
   "source": [
    "## 4. Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5facd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images from each class\n",
    "import random\n",
    "\n",
    "def show_samples(image_paths, labels, class_label, n_samples=5):\n",
    "    # Get images of specific class\n",
    "    class_images = [path for path, label in zip(image_paths, labels) if label == class_label]\n",
    "    \n",
    "    if len(class_images) < n_samples:\n",
    "        n_samples = len(class_images)\n",
    "    \n",
    "    # Random sample\n",
    "    samples = random.sample(class_images, n_samples)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, n_samples, figsize=(15, 3))\n",
    "    if n_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    class_name = \"Real\" if class_label == 0 else \"AI-Generated\"\n",
    "    fig.suptitle(f\"Sample {class_name} Images\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for ax, img_path in zip(axes, samples):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(os.path.basename(img_path), fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show real images\n",
    "print(\"Real Images:\")\n",
    "show_samples(image_paths, labels, class_label=0, n_samples=5)\n",
    "\n",
    "# Show AI-generated images\n",
    "print(\"\\nAI-Generated Images:\")\n",
    "show_samples(image_paths, labels, class_label=1, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ebdf1",
   "metadata": {},
   "source": [
    "## 5. Image Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d646213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image dimensions\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "# Sample 100 random images\n",
    "sample_paths = random.sample(image_paths, min(100, len(image_paths)))\n",
    "\n",
    "for img_path in sample_paths:\n",
    "    img = Image.open(img_path)\n",
    "    widths.append(img.width)\n",
    "    heights.append(img.height)\n",
    "\n",
    "print(f\"Image Size Statistics (from {len(sample_paths)} samples):\")\n",
    "print(f\"  Width: {np.mean(widths):.0f} ¬± {np.std(widths):.0f} px\")\n",
    "print(f\"  Height: {np.mean(heights):.0f} ¬± {np.std(heights):.0f} px\")\n",
    "print(f\"  Min: {min(widths)}x{min(heights)}\")\n",
    "print(f\"  Max: {max(widths)}x{max(heights)}\")\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(widths, heights, alpha=0.5)\n",
    "plt.xlabel('Width (px)', fontsize=12)\n",
    "plt.ylabel('Height (px)', fontsize=12)\n",
    "plt.title('Image Dimensions Distribution', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.axhline(y=224, color='r', linestyle='--', label='Model input size (224x224)')\n",
    "plt.axvline(x=224, color='r', linestyle='--')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f4f8e0",
   "metadata": {},
   "source": [
    "## 6. Train/Val/Test Split Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_paths, train_labels, val_paths, val_labels, test_paths, test_labels = split_dataset(\n",
    "    image_paths, labels,\n",
    "    train_split=config['data']['train_split'],\n",
    "    val_split=config['data']['val_split'],\n",
    "    test_split=config['data']['test_split'],\n",
    "    random_seed=config['seed']\n",
    ")\n",
    "\n",
    "# Visualize split\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "splits = ['Train', 'Validation', 'Test']\n",
    "real_counts = [\n",
    "    train_labels.count(0),\n",
    "    val_labels.count(0),\n",
    "    test_labels.count(0)\n",
    "]\n",
    "ai_counts = [\n",
    "    train_labels.count(1),\n",
    "    val_labels.count(1),\n",
    "    test_labels.count(1)\n",
    "]\n",
    "\n",
    "x = np.arange(len(splits))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, real_counts, width, label='Real', color='#2ecc71', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, ai_counts, width, label='AI-Generated', color='#e74c3c', alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('Number of Images', fontsize=12)\n",
    "ax.set_title('Train/Val/Test Split Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(splits)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "add_labels(bars1)\n",
    "add_labels(bars2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aeaa0d",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_transforms\n",
    "import albumentations as A\n",
    "\n",
    "# Get a sample image\n",
    "sample_path = random.choice(image_paths)\n",
    "image = np.array(Image.open(sample_path).convert('RGB'))\n",
    "\n",
    "# Get augmentation transforms\n",
    "transform = get_transforms(config, is_training=True)\n",
    "\n",
    "# Generate augmented versions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Augmented versions\n",
    "for i in range(1, 6):\n",
    "    augmented = transform(image=image)['image']\n",
    "    axes[i].imshow(augmented)\n",
    "    axes[i].set_title(f'Augmented {i}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Augmentations applied:\")\n",
    "print(\"  - Random horizontal flip\")\n",
    "print(\"  - Random rotation\")\n",
    "print(\"  - Color jittering (brightness, contrast, saturation)\")\n",
    "print(\"  - Gaussian noise\")\n",
    "print(\"  - Random blur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9795d02",
   "metadata": {},
   "source": [
    "## 8. Ready to Train?\n",
    "\n",
    "If all checks pass, you're ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dca5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dataset Readiness Checklist\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = []\n",
    "\n",
    "# Check 1: Sufficient data\n",
    "if total_images >= 500:\n",
    "    print(\"‚úì Sufficient images (>= 500)\")\n",
    "    checks.append(True)\n",
    "else:\n",
    "    print(f\"‚úó Not enough images ({total_images} < 500)\")\n",
    "    checks.append(False)\n",
    "\n",
    "# Check 2: Balanced classes\n",
    "balance = min(real_count, ai_count) / max(real_count, ai_count)\n",
    "if balance >= 0.8:\n",
    "    print(\"‚úì Classes are balanced (ratio >= 0.8)\")\n",
    "    checks.append(True)\n",
    "else:\n",
    "    print(f\"‚úó Classes imbalanced (ratio: {balance:.2f})\")\n",
    "    checks.append(False)\n",
    "\n",
    "# Check 3: Image quality\n",
    "avg_size = np.mean(widths + heights)\n",
    "if avg_size >= 224:\n",
    "    print(\"‚úì Image resolution adequate\")\n",
    "    checks.append(True)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Images are small (avg: {avg_size:.0f}px)\")\n",
    "    checks.append(True)  # Still passable\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "if all(checks):\n",
    "    print(\"\\nüöÄ Dataset is ready! You can start training:\")\n",
    "    print(\"   python src/train.py\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Please address the issues above before training.\")\n",
    "    print(\"   You can still try training, but results may be suboptimal.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
